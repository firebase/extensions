The `firestore-bigquery-change-tracker` package is a dependency for the official Firebase Extension [_Stream Firestore to BigQuery_](https://github.com/firebase/extensions/tree/master/firestore-bigquery-export), [_schema views script_](https://github.com/firebase/extensions/blob/master/firestore-bigquery-export/guides/GENERATE_SCHEMA_VIEWS.md) & the [_import Firestore documents script_](https://github.com/firebase/extensions/blob/master/firestore-bigquery-export/guides/IMPORT_EXISTING_DOCUMENTS.md).

Its main purpose is to initialize & update the BigQuery table & view generated by using the `firestore-bigquery-export` extension.

## Partitioning Configuration Guide
The partitioning system allows BigQuery tables to be partitioned for better query performance and cost optimization. There are two main types of partitioning:

1. **Ingestion-time partitioning** - Partitions by when data arrives in BigQuery
2. **Field-based partitioning** - Partitions by a specific field value

## Configuration Parameters

### Core Parameters
- `timePartitioning` - The partition granularity: "HOUR", "DAY", "MONTH", "YEAR"
- `timePartitioningField` - The BigQuery column name to partition by
- `timePartitioningFieldType` - The BigQuery data type: "TIMESTAMP", "DATE", "DATETIME"
- `timePartitioningFirestoreField` - The Firestore document field to extract partition value from

## Configuration Scenarios

### 1. No Partitioning (Default)
```yaml
timePartitioning: null/undefined/""
```
- No partitioning is applied
- All validation checks return early

### 2. Ingestion-Time Partitioning
```yaml
timePartitioning: "DAY"  # or HOUR, MONTH, YEAR
timePartitioningField: null/undefined
```
- Partitions by `_PARTITIONTIME` (when data arrives in BigQuery)
- No custom field is added to schema
- No Firestore field mapping needed

### 3. Built-in Field Partitioning (Without Custom Type)
```yaml
timePartitioning: "DAY"
timePartitioningField: "timestamp"  # or document_name, event_id, operation
timePartitioningFieldType: null/undefined
timePartitioningFirestoreField: null/undefined
```
- Uses existing schema fields like `timestamp`
- No custom field added to schema
- No Firestore field mapping needed
- **IMPORTANT**: The partition value comes from the system-generated field, NOT from document data
- `getPartitionValue()` returns empty object `{}` in this case

### 4. Built-in Field Partitioning (With Custom Type)
```yaml
timePartitioning: "DAY"
timePartitioningField: "timestamp"
timePartitioningFieldType: "DATE"  # Override default TIMESTAMP type
timePartitioningFirestoreField: "createdAt"  # REQUIRED when type is specified
```
- Uses existing field name but extracts value from Firestore document
- Requires Firestore field mapping when field type is specified
- Extracts value from specified Firestore field and converts to specified type

### 5. Custom Field Partitioning
```yaml
timePartitioning: "MONTH"
timePartitioningField: "end_date"  # Custom field name
timePartitioningFieldType: "DATETIME"  # Optional, defaults to TIMESTAMP
timePartitioningFirestoreField: "endDate"  # REQUIRED
```
- Creates new field in BigQuery schema
- Must specify Firestore field to extract value from
- Supports string or date/timestamp values from Firestore

## Validation Rules

### Invalid Configurations

1. **Missing Firestore field for custom fields**
   ```yaml
   timePartitioning: "DAY"
   timePartitioningField: "custom_date"
   timePartitioningFirestoreField: null  # ❌ Invalid
   ```

2. **Missing Firestore field when type is specified**
   ```yaml
   timePartitioning: "DAY"
   timePartitioningField: "timestamp"
   timePartitioningFieldType: "DATE"
   timePartitioningFirestoreField: null  # ❌ Invalid
   ```

3. **Invalid partition type**
   ```yaml
   timePartitioning: "WEEKLY"  # ❌ Not supported
   ```

4. **Invalid field type**
   ```yaml
   timePartitioningFieldType: "STRING"  # ❌ Not supported
   ```

5. **HOUR partitioning with DATE field type**
   ```yaml
   timePartitioning: "HOUR"
   timePartitioningFieldType: "DATE"  # ❌ Invalid combination
   ```

6. **Field-based config without field name**
   ```yaml
   timePartitioning: "DAY"
   timePartitioningFieldType: "DATE"
   timePartitioningFirestoreField: "createdAt"
   timePartitioningField: null  # ❌ Invalid - field name required
   ```

7. **Already partitioned table**
   - Cannot add partitioning to existing partitioned tables
   - Must create new table

8. **Missing table reference**
   - Partitioning class requires valid table reference for most operations

## Value Extraction Flow (`getPartitionValue`)

### Return Conditions
The method returns an empty object `{}` when:
- No `timePartitioningField` is configured
- No `timePartitioningFirestoreField` is configured
- The field value is not found in the document
- The field value cannot be converted to the expected format
- Both `data` and `oldData` are null

### For String Values
```javascript
if (typeof value === "string") {
  return value; // Pass through as-is, no validation
}
```

### For Date/Timestamp Values
1. **Firebase Timestamp** → Convert to BigQuery format
2. **Timestamp-like object** (`{_seconds, _nanoseconds}`) → Convert to Timestamp → Format
   - Must have valid numeric `_seconds` and `_nanoseconds`
   - Invalid numbers (NaN, Infinity) cause conversion failure
3. **Object with `toDate()` method** → Call toDate() → Format
   - Must return a valid Date object
4. **Native Date object** → Format directly
   - Must be a valid date (not NaN)

### Formatting by Type
- **TIMESTAMP** (default): `BigQuery.timestamp(date).value`
- **DATETIME**: `BigQuery.datetime(date.toISOString()).value`
- **DATE**: `BigQuery.date(date.toISOString().substring(0, 10)).value`

## Error Handling

1. **Invalid date values** → Log error via `logs.firestoreTimePartitionFieldError()`, return empty object
2. **Missing field values** → Return empty object (row inserted without partition value)
3. **Non-string/non-date values** → Log error, return empty object
4. **DELETE operations** → Use `oldData` instead of `data`
5. **Invalid timestamp values** → Console warning, return null from converter

## Special Cases

### Built-in Fields
These fields exist in the default schema:
- `timestamp` - The commit timestamp from Firestore
- `document_name` - Full document path
- `event_id` - Change event ID
- `operation` - CREATE/UPDATE/DELETE

**Important**: When using built-in fields without `timePartitioningFirestoreField`, the partition uses the system-generated values, not document data.

### Default Field Type
When `timePartitioningFieldType` is not specified:
- The `getNewPartitionField()` function defaults to "TIMESTAMP"
- This only applies when creating new fields in the schema

### Table Update Behavior
- **New table**: Partitioning configured during creation
- **Existing non-partitioned table**: Can add partitioning field to schema
- **Existing partitioned table**: Cannot modify partitioning

## Common Patterns

### 1. Simple Daily Partitioning by System Timestamp
```yaml
timePartitioning: "DAY"
timePartitioningField: "timestamp"
# Uses system-generated timestamp, not document data
```

### 2. Daily Partitioning by Document Field
```yaml
timePartitioning: "DAY"
timePartitioningField: "timestamp"
timePartitioningFieldType: "TIMESTAMP"
timePartitioningFirestoreField: "createdAt"  # Extract from document
```

### 3. Monthly Partitioning by Custom Date Field
```yaml
timePartitioning: "MONTH"
timePartitioningField: "invoice_date"
timePartitioningFieldType: "DATE"
timePartitioningFirestoreField: "invoiceDate"
```

### 4. Hourly Partitioning for High-Volume Data
```yaml
timePartitioning: "HOUR"
timePartitioningField: "event_time"
timePartitioningFieldType: "TIMESTAMP"
timePartitioningFirestoreField: "eventTimestamp"
```

## Key Implementation Notes

1. **String values are not validated** - Any string passes through unchanged
2. **Empty objects from `getPartitionValue()`** don't prevent row insertion
3. **Built-in fields have dual behavior** depending on whether Firestore field is specified
4. **Field type validation** allows undefined/null as valid (treated as no restriction)
5. **The partitioning handler** is created for each batch of events in the `record()` method